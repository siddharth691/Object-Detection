{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = \n",
    "image_width = \n",
    "image_height = \n",
    "image_size = \n",
    "\n",
    "\n",
    "\n",
    "no_grid = \n",
    "no_classes = \n",
    "no_boxes_per_cell = \n",
    "\n",
    "#Scales\n",
    "class_scale = \n",
    "confidence_obj_scale = \n",
    "confidence_noobj_scale = \n",
    "\n",
    "def conv_layers_typ1(x):\n",
    "    \n",
    "    #Repeat Convolutional layer 1\n",
    "    x1 = tf.layers.conv2d(x, 256,1)\n",
    "\n",
    "    #Repeat convolutional layer 2\n",
    "    x2 = tf.layers.conv2d(x1, 512, 3)\n",
    "    \n",
    "    return x2\n",
    "\n",
    "\n",
    "def conv_layers_typ2(x):\n",
    "    \n",
    "    #Repeat convolutional layer 1\n",
    "    x1 = tf.layers.conv2d(x, 512, 1)\n",
    "    \n",
    "    #Repeat convolutional layer 2\n",
    "    \n",
    "    x2 = tf.layers.conv2d(x1, 1024, 3)\n",
    "    \n",
    "    return x2\n",
    "\n",
    "\n",
    "def yolo_model():\n",
    "    \n",
    "    with tf.variable_scope('yolo_model'):\n",
    "        \n",
    "        #Convolutional layer 1\n",
    "        x1 = tf.layers.conv2d(x,64,7,2,'same')\n",
    "\n",
    "        #Max pool layer 1\n",
    "        x2 = tf.layers.max_pooling2d(x1,2,2)\n",
    "        \n",
    "        #Convolutional layer 2\n",
    "        x3 = tf.layers.conv2d(x2, 192, 3)\n",
    "        \n",
    "        #Max pool layer 2\n",
    "        x4 = tf.layers.max_pooling2d(x3,2,2)\n",
    "        \n",
    "        #Convolutional layer 3\n",
    "        x5 = tf.layers.conv2d(x4, 128,1)\n",
    "        \n",
    "        #Convolutional layer 4\n",
    "        x6 = tf.layers.conv2d(x5, 256, 3)\n",
    "        \n",
    "        #Convolutional layer 5\n",
    "        x7 = tf.layers.conv2d(x6, 256, 1)\n",
    "        \n",
    "        #Convolutional layer 6\n",
    "        x8 = tf.layers.conv2d(x7, 512, 3)\n",
    "        \n",
    "        #Max pool layer 3\n",
    "        x9 = tf.layers.max_pooling2d(x8, 2,2)\n",
    "        \n",
    "        #Convolutional layers 7,8\n",
    "        x10 = conv_layers_typ1(x9)\n",
    "        \n",
    "        #Convolutional layers 9,10\n",
    "        x11 = conv_layers_typ1(x10)\n",
    "        \n",
    "        #Convolutional layers 11,12\n",
    "        x12 = conv_layers_typ1(x11)\n",
    "        \n",
    "        #Convolutional layers 13,14\n",
    "        x13 = conv_layers_typ1(x12)\n",
    "        \n",
    "        #Convolutional layer 15\n",
    "        x14 = tf.layers.conv2d(x13, 512, 1)\n",
    "        \n",
    "        #Convolutional layer 16\n",
    "        x15 = tf.layers.conv2d(x14, 1024, 3)\n",
    "        \n",
    "        #Max pool layer 4\n",
    "        x16 = tf.layers.max_pooling2d(x15, 2,2)\n",
    "        \n",
    "        #Convolutional layer 17, 18\n",
    "        x17 = conv_layers_typ2(x16)\n",
    "        \n",
    "        #Convolutional layer 19, 20\n",
    "        x18 = conv_layers_typ2(x17)\n",
    "        \n",
    "        #Convolutional layer 21\n",
    "        x19 = tf.layers.conv2d(x18, 1024, 3)\n",
    "        \n",
    "        #Convolutional layer 22\n",
    "        x20 = tf.layers.conv2d(x19, 1024, 3, 2)\n",
    "        \n",
    "        #Convolutional layer 23\n",
    "        x21 = tf.layers.conv2d(x20, 1024, 3)\n",
    "        \n",
    "        #Convolutional layer 24\n",
    "        x22 = tf.layers.conv2d(x21, 1024, 3)\n",
    "        \n",
    "        #Fully connected layer 1\n",
    "        flat1 = tf.contrib.layers.flatten(x22)\n",
    "        x23 = tf.layers.dense(flat1, 512)\n",
    "        \n",
    "        #Fully connected layer 2\n",
    "        flat2 = tf.contrib.layers.flatten(x23)\n",
    "        x24 = tf.layers.dense(flat2, 4096)\n",
    "        \n",
    "        #Reshaping the output of the last layer to the size (batch size, S,S,(5*B+C))\n",
    "        out = tf.reshape(x24, (-1, 7,7,30))\n",
    "        \n",
    "        return out\n",
    "    \n",
    "def calc_iou_single(label_box, predict_box):\n",
    "    \n",
    "    #TODO: convert the relative x y with respect to grid cell to absolute x y\n",
    "    \n",
    "    #Calculating the actual label box upper left x,y and lower right x,y\n",
    "    lxa = label_box[0]\n",
    "    lya = label_box[1]\n",
    "    lxb = lxa + label_box[2]*image_width\n",
    "    lyb = lya + label_box[3]*image_height\n",
    "    \n",
    "    #Calculating the predicted box upper left x,y and lower right x,y\n",
    "    pxa = predict_box[0]\n",
    "    pya = predict_box[1]\n",
    "    pxb = pxa + label_box[2]*image_width\n",
    "    pyb = pya + label_box[3]*image_height\n",
    "    \n",
    "    #Calculating the intersection box upper left x,y and lower right x,y\n",
    "    ixa = np.max(lxa, pxa)\n",
    "    iya = np.max(lya, pya)\n",
    "    ixb = np.min(lxb, pxb)\n",
    "    iyb = np.min(lyb, pyb)\n",
    "    \n",
    "    #Calculating the area of the intersection box\n",
    "    iArea = (ixb - ixa + 1)*(iyb - iya + 1)\n",
    "    \n",
    "    #Calculating the area of label box and predicted box\n",
    "    lArea = (lxb - lxa +1)*(lxb - lxa + 1)\n",
    "    pArea = (pxb - pxa + 1)*(pyb - pyb + 1)\n",
    "    \n",
    "    \n",
    "    #Calculating and returning IOU\n",
    "    iou = iArea/(lArea + pArea - iArea)\n",
    "    \n",
    "def cal_iou(predict_boxes, label_boxes):\n",
    "    \"\"\"\n",
    "    Calculates IOU in multidimension\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "    predict_boxes (batch_size, no_grid, no_grid, boxes_per_cell, 4): predicted boxes (corrected)\n",
    "    label_boxes (batch_size, no_grid, no_grid, boxes_per_cell, 4): label boxes\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    IOU (batch_size, no_grid, no_grid, boxes_per_cell) : multidimensional IOU (truncated between 0 and 1)\n",
    "    \"\"\"\n",
    "    #Calculating the predicted box upper left x,y and lower right x,y\n",
    "    boxes1 = tf.stack([predict_boxes[:,:,:,:,0],\n",
    "                       predict_boxes[:,:,:,:,1],\n",
    "                       (predict_boxes[:,:,:,:,0] + predict_boxes[:,:,:,:,2]),\n",
    "                       (predict_boxes[:,:,:,:,1] + predict_boxes[:,:,:,:,3])])\n",
    "    boxes1 = tf.transpose(boxes1, [1,2,3,4,0])\n",
    "    \n",
    "    #Calculating the actual label box upper left x,y and lower right x,y\n",
    "    boxes2 = tf.stack([label_boxes[:,:,:,:,0],\n",
    "                       label_boxes[:,:,:,:,1],\n",
    "                       (label_boxes[:,:,:,:,0] + label_boxes[:,:,:,:,2]),\n",
    "                       (label_boxes[:,:,:,:,1] + label_boxes[:,:,:,:,3])])\n",
    "    boxes2 = tf.transpose(boxes2, [1,2,3,4,0])\n",
    "    \n",
    "    #Calculating the intersection box upper left x,y and lower right x,y\n",
    "    ul = tf.maximum(boxes1[:,:,:,:,:2], boxes2[:,:,:,:,:2])\n",
    "    lr = tf.minimum(boxes1[:,:,:,:,2:], boxes2[:,:,:,:,2:])\n",
    "    \n",
    "    #Calculating the area of the intersection box\n",
    "    idiff = tf.maximum(0.0, lr - ul)\n",
    "    iArea = idiff[:,:,:,:,0] * idiff[:,:,:,:,1]\n",
    "    \n",
    "    #Calculating the area of label box and predicted box\n",
    "    lArea = (boxes2[:,:,:,:,2] - boxes2[:,:,:,:,0])*(boxes2[:,:,:,:,3] - boxes2[:,:,:,:,1])\n",
    "    pArea = (boxes1[:,:,:,:,2] - boxes1[:,:,:,:,0])*(boxes1[:,:,:,:,3] - boxes1[:,:,:,:,1])\n",
    "    \n",
    "    \n",
    "    #Calculating union area\n",
    "    uArea = tf.maximum(lArea + pArea - iArea, 1e-10)\n",
    "    \n",
    "    #Clipping and returning the IOU\n",
    "    return tf.clip_by_value(iArea / uArea . 0.0, 1.0)\n",
    "    \n",
    "    \n",
    "def loss(prediction, labels):\n",
    "    \n",
    "    \"\"\"\n",
    "    #Dimensions of labels:\n",
    "    Labels will be of dimension [batch_size, no_grid, no_grid, 5 (1st dimension would be confidence (1 if object \n",
    "     is present otherwise 0), 2nd and 3rd dimension would be upper x and y, 4th and 5th would be width and height)+ C (class probability)]\n",
    "     \n",
    "    Labels are not of the shape [batch_size, no_grid, no_grid, 5*B+C] because for each bounding box predictor per cell\n",
    "    dimensions of the object are same\n",
    "     \n",
    "    #Dimensions of prediction:\n",
    "    Prediction will be of dimension [batch_size, no_grid, no_grid, 5*B+C]\n",
    "    in the 4th dimension: (1st B are confidence score, next 4*B are [x,y,w,h] repeated B times, and last C are class prob)\n",
    "    \"\"\" \n",
    "    \n",
    "    ### extracting classes and boxes from labels\n",
    "    label_classes = tf.reshape(labels[:,:,:,5:], [batch_size, no_grid, no_grid, no_classes])\n",
    "    label_boxes = tf.reshape(labels[:,:,:,1:5], [batch_size, no_grid, no_grid, 1, 4])\n",
    "    label_boxes = tf.tile(label_boxes, [1,1,1,boxes_per_cell,1]) / image_size\n",
    "    \n",
    "    ### extracting classes, boxes and confidence from prediction\n",
    "    predict_classes = tf.reshape(prediction[:,:,:,5*boxes_per_cell:], [batch_size, no_grid, no_grid, no_classes])\n",
    "    predict_boxes = tf.reshape(prediction[:,:,:,boxes_per_cell:5*boxes_per_cell], [batch_size, no_grid, no_grid, boxes_per_cell, 4])\n",
    "    predict_confidence = tf.reshape(prediction[:,:,:,:boxes_per_cell], [batch_size, no_grid, no_grid, boxes_per_cell])\n",
    "\n",
    "    ###Calculating offset for correction of prediction and formatting of labels\n",
    "    offset = np.transpose(np.reshape(np.array([np.arange(no_grid)] * no_grid * boxes_per_cell), (boxes_per_cell, no_grid, no_grid)), (1, 2, 0))\n",
    "    offset = tf.constant(offset, dtype = tf.float32)\n",
    "    offset = tf.reshape(offset, [1, no_grid, no_grid, boxes_per_cell])\n",
    "    offset = tf.tile(offset, [batch_size, 1, 1, 1])\n",
    "    \n",
    "    ###Correction and formatting\n",
    "    #Correcting predict_boxes for calculating IOU\n",
    "    corr_predict_boxes = tf.stack([(predict_boxes[:,:,:,:,0] + offset) / no_grid,\n",
    "                                  (predict_boxes[:,:,:,:,1] + np.transpose(offset, (0,2,1,3))) / no_grid,\n",
    "                                  tf.square(predict_boxes[:,:,:,:,2]),\n",
    "                                  tf.square(predict_boxes[:,:,:,:,3])])\n",
    "    corr_predict_boxes = tf.transpose(corr_predict_boxes, [1,2,3,4,0]) #As tf.stack appends new dimension in the front\n",
    "    \n",
    "    #Formatting label boxes according by normalization and subtracting offset\n",
    "    format_label_boxes = tf.stack([label_boxes[:,:,:,:,0] * no_grid - offset,\n",
    "                                   label_boxes[:,:,:,:,1] + np.transpose(offset, (0,2,1,3)) / no_grid,\n",
    "                                   tf.sqrt(label_boxes[:,:,:,:,2]),\n",
    "                                   tf.sqrt(label_boxes[:,:,:,:,3])])\n",
    "    format_label_boxes = tf.transpose(format_label_boxes, [1,2,3,4,0]) #As tf.stack appends new dimension in the front\n",
    "    \n",
    "    #Calculated IOU for each box (batch_size, no_grid, no_grid, boxes_per_cell)\n",
    "    calc_iou_boxes = calc_iou(corr_predict_boxes, label_boxes)\n",
    "    \n",
    "    ###Calculating difference masks\n",
    "    #Mask if the object is present in the cell or not (batch_size, no_grid, no_grid, 1)\n",
    "    object_presence_map = tf.reshape(labels[:,:,:,0], [batch_size, no_grid, no_grid, 1]) #if object is present in the grid cell or not\n",
    "    \n",
    "    #Calculating object max (float 1,0 of shape (batch_size, no_grid, no_grid, boxes_per_cell))\n",
    "    iou_mask = tf.reduce_max(calc_iou_boxes, axis = 3, keepdims = True)\n",
    "    iou_mask = tf.cast((calc_iou_boxes>=iou_mask), dtype=tf.float64)\n",
    "    object_mask = iou_mask * object_presence_map\n",
    "    \n",
    "    #Calculating no object mask (float 1,0 of shape (batch_size, no_grid, no_grid, boxes_per_cell))\n",
    "    no_object_mask = tf.ones_like(object_mask, dtype=tf.float64) - object_mask\n",
    "    \n",
    "    #Calculating coordinate mask (float 1,0 of shape (batch_size, no_grid, no_grid, boxes_per_cell, 1))\n",
    "    coord_mask = tf.expand_dims(object_mask, 4)\n",
    "    \n",
    "    \n",
    "    ### Losses\n",
    "    #Class loss\n",
    "    class_loss = class_scale * tf.reduce_mean(tf.reduce_sum(tf.square(object_presence_map*(predict_classes - label_classes)), axis = [1,2,3]))\n",
    "    \n",
    "    #Calculating confidence loss\n",
    "    confidence_obj_loss = object_mask * (predict_confidence - calc_iou_boxes)  # we want to make confidence score same as iou when obj is present\n",
    "    confidence_obj_loss = confidence_obj_scale * tf.reduce_mean(tf.reduce_sum(tf.square(confidence_obj_loss), axis = [1,2,3]))\n",
    "    \n",
    "    confidence_noobj_loss = no_object_mask * (predicted_confidence) #we want to make the confidence score 0 when obj is not present\n",
    "    confidence_noobj_loss = confidence_noobj_scale * tf.reduce_mean(tf.reduce_sum(tf.square(confidence_noobj_loss), axis = [1,2,3]))\n",
    "    \n",
    "    #Calculating coordinates loss\n",
    "    coord_loss = coord_mask * (predict_boxes - format_label_boxes)\n",
    "    coord_loss = coord_scale * tf.reduce_mean(tf.reduce_sum(tf.square(coord_loss), axis = [1,2,3]))\n",
    "    \n",
    "    #Adding up the losses\n",
    "    total_loss = class_loss + confidence_obj_loss + confidence_noobj_loss + coord_loss\n",
    "    \n",
    "#     sess = tf.Session()\n",
    "    \n",
    "#     image_placeholder = tf.placeholder(\"float\", (batch_size, 2048, 2048, 3))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5)\n",
      "[[ 2  3  4]\n",
      " [ 4 56  7]]\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[1,2,3,4,5],[3,4,56,7,2]])\n",
    "print(a.get_shape())\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(a[:,1:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 8, 8, 5)\n",
      "(50, 8, 8, 1)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "cell_size = 8\n",
    "boxes_per_cell = 5\n",
    "\n",
    "a1 = tf.random_uniform(np.array([batch_size, cell_size, cell_size, boxes_per_cell, 4]))\n",
    "a2 = tf.random_uniform(np.array([batch_size, cell_size, cell_size, boxes_per_cell, 4]))\n",
    "\n",
    "c = calc_iou(a1, a2)\n",
    "print(c.get_shape())\n",
    "d = tf.reduce_max(c, 3, keepdims=True)\n",
    "print(d.get_shape())\n",
    "# with tf.Session() as sess:\n",
    "#     print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_iou(boxes1, boxes2, scope = 'iou'):\n",
    "    \n",
    "    with tf.variable_scope(scope):\n",
    "        boxes1 = tf.stack([boxes1[:, :, :, :, 0] - boxes1[:, :, :, :, 2] / 2.0,\n",
    "                           boxes1[:, :, :, :, 1] - boxes1[:, :, :, :, 3] / 2.0,\n",
    "                           boxes1[:, :, :, :, 0] + boxes1[:, :, :, :, 2] / 2.0,\n",
    "                           boxes1[:, :, :, :, 1] + boxes1[:, :, :, :, 3] / 2.0])\n",
    "        boxes1 = tf.transpose(boxes1, [1, 2, 3, 4, 0])\n",
    "\n",
    "        boxes2 = tf.stack([boxes2[:, :, :, :, 0] - boxes2[:, :, :, :, 2] / 2.0,\n",
    "                           boxes2[:, :, :, :, 1] - boxes2[:, :, :, :, 3] / 2.0,\n",
    "                           boxes2[:, :, :, :, 0] + boxes2[:, :, :, :, 2] / 2.0,\n",
    "                           boxes2[:, :, :, :, 1] + boxes2[:, :, :, :, 3] / 2.0])\n",
    "        boxes2 = tf.transpose(boxes2, [1, 2, 3, 4, 0])\n",
    "\n",
    "        lu = tf.maximum(boxes1[:, :, :, :, :2], boxes2[:, :, :, :, :2])\n",
    "        rd = tf.minimum(boxes1[:, :, :, :, 2:], boxes2[:, :, :, :, 2:])\n",
    "\n",
    "        intersection = tf.maximum(0.0, rd - lu)\n",
    "        inter_square = intersection[:, :, :, :, 0] * intersection[:, :, :, :, 1]\n",
    "\n",
    "        square1 = (boxes1[:, :, :, :, 2] - boxes1[:, :, :, :, 0]) * (boxes1[:, :, :, :, 3] - boxes1[:, :, :, :, 1])\n",
    "        square2 = (boxes2[:, :, :, :, 2] - boxes2[:, :, :, :, 0]) * (boxes2[:, :, :, :, 3] - boxes2[:, :, :, :, 1])\n",
    "\n",
    "        union_square = tf.maximum(square1 + square2 - inter_square, 1e-10)\n",
    "\n",
    "    return tf.clip_by_value(inter_square / union_square, 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_boxes = tf.reshape(predicts[:, self.boundary2:], [settings.batch_size, self.cell_size, self.cell_size, self.boxes_per_cell, 4])\n",
    "#predict_boxes shape = (batch_size, cell_size, cell_size, boxes_per_cell, 4)\n",
    "\n",
    "\n",
    "boxes = tf.reshape(labels[:, :, :, 1:5], [settings.batch_size, self.cell_size, self.cell_size, 1, 4])\n",
    "boxes = tf.tile(boxes, [1, 1, 1, self.boxes_per_cell, 1]) / self.image_size\n",
    "#Boxes shape (batch_size, cell_size, cell_size, boxes_per_cell, 4)\n",
    "\n",
    "offset = tf.constant(self.offset, dtype = tf.float32)\n",
    "offset = tf.reshape(offset, [1, self.cell_size, self.cell_size, self.boxes_per_cell])\n",
    "offset = tf.tile(offset, [settings.batch_size, 1, 1, 1])\n",
    "predict_boxes_tran = tf.stack([(predict_boxes[:, :, :, :, 0] + offset) / self.cell_size,\n",
    "                               (predict_boxes[:, :, :, :, 1] + tf.transpose(offset, (0, 2, 1, 3))) / self.cell_size,\n",
    "                               tf.square(predict_boxes[:, :, :, :, 2]),\n",
    "                               tf.square(predict_boxes[:, :, :, :, 3])])\n",
    "predict_boxes_tran = tf.transpose(predict_boxes_tran, [1, 2, 3, 4, 0])\n",
    "#predict_boxes tran = shape (batch_size, cell_size,cell_size, boxes_per_cell, 4) but with offset added and normalized for cell size\n",
    "\n",
    "iou_predict_truth = self.calc_iou(predict_boxes_tran, boxes)\n",
    "\n",
    "object_mask = tf.reduce_max(iou_predict_truth, 3, keep_dims=True)\n",
    "object_mask = tf.cast((iou_predict_truth >= object_mask), tf.float32) * response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2, 2)\n",
      "[[[ 1  2]\n",
      "  [ 3  4]]\n",
      "\n",
      " [[ 5  6]\n",
      "  [ 7  8]]\n",
      "\n",
      " [[ 9 10]\n",
      "  [11 12]]]\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[1,2],[3,4]])\n",
    "b = tf.constant([[5,6],[7,8]])\n",
    "d = tf.constant([[9,10],[11,12]])\n",
    "c = tf.stack([a,b,d])\n",
    "print(c.get_shape())\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "[[1 3]\n",
      " [2 4]]\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[1, 2], [3, 4]])\n",
    "at = tf.transpose(a, [1,0])\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(a))\n",
    "    print(sess.run(at))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1, 2, 3, 4],\n",
      "       [1, 2, 3, 4],\n",
      "       [1, 2, 3, 4]], dtype=int32)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "vec = tf.constant([1, 2, 3, 4])\n",
    "multiply = tf.constant([3])\n",
    "\n",
    "matrix = tf.reshape(tf.tile(vec, multiply), [ multiply[0], tf.shape(vec)[0]])\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run([matrix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 7, 7, 30)\n"
     ]
    }
   ],
   "source": [
    "S = 7\n",
    "B = 2\n",
    "C = 20\n",
    "batch_size = 50\n",
    "a = np.random.rand(batch_size, S, S, 5*B+C)\n",
    "labels = tf.convert_to_tensor(a)\n",
    "print(labels.get_shape())\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     print(sess.run(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 1, 2, 3, 4, 5, 6],\n",
       "        [0, 1, 2, 3, 4, 5, 6],\n",
       "        [0, 1, 2, 3, 4, 5, 6],\n",
       "        [0, 1, 2, 3, 4, 5, 6],\n",
       "        [0, 1, 2, 3, 4, 5, 6],\n",
       "        [0, 1, 2, 3, 4, 5, 6],\n",
       "        [0, 1, 2, 3, 4, 5, 6]],\n",
       "\n",
       "       [[0, 1, 2, 3, 4, 5, 6],\n",
       "        [0, 1, 2, 3, 4, 5, 6],\n",
       "        [0, 1, 2, 3, 4, 5, 6],\n",
       "        [0, 1, 2, 3, 4, 5, 6],\n",
       "        [0, 1, 2, 3, 4, 5, 6],\n",
       "        [0, 1, 2, 3, 4, 5, 6],\n",
       "        [0, 1, 2, 3, 4, 5, 6]],\n",
       "\n",
       "       [[0, 1, 2, 3, 4, 5, 6],\n",
       "        [0, 1, 2, 3, 4, 5, 6],\n",
       "        [0, 1, 2, 3, 4, 5, 6],\n",
       "        [0, 1, 2, 3, 4, 5, 6],\n",
       "        [0, 1, 2, 3, 4, 5, 6],\n",
       "        [0, 1, 2, 3, 4, 5, 6],\n",
       "        [0, 1, 2, 3, 4, 5, 6]],\n",
       "\n",
       "       [[0, 1, 2, 3, 4, 5, 6],\n",
       "        [0, 1, 2, 3, 4, 5, 6],\n",
       "        [0, 1, 2, 3, 4, 5, 6],\n",
       "        [0, 1, 2, 3, 4, 5, 6],\n",
       "        [0, 1, 2, 3, 4, 5, 6],\n",
       "        [0, 1, 2, 3, 4, 5, 6],\n",
       "        [0, 1, 2, 3, 4, 5, 6]],\n",
       "\n",
       "       [[0, 1, 2, 3, 4, 5, 6],\n",
       "        [0, 1, 2, 3, 4, 5, 6],\n",
       "        [0, 1, 2, 3, 4, 5, 6],\n",
       "        [0, 1, 2, 3, 4, 5, 6],\n",
       "        [0, 1, 2, 3, 4, 5, 6],\n",
       "        [0, 1, 2, 3, 4, 5, 6],\n",
       "        [0, 1, 2, 3, 4, 5, 6]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape([np.arange(7)] * 7 * 5, (5, 7, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = np.transpose(np.reshape([np.arange(7)] * 7 * 5, (5, 7, 7)), (1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = tf.constant(offset, dtype = tf.float32)\n",
    "offset = tf.reshape(offset, [1, 7, 7, 5])\n",
    "offset = tf.tile(offset, [50, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 7, 7, 5)\n"
     ]
    }
   ],
   "source": [
    "print(offset.get_shape())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [2. 2. 2. 2. 2.]\n",
      "   ...\n",
      "   [4. 4. 4. 4. 4.]\n",
      "   [5. 5. 5. 5. 5.]\n",
      "   [6. 6. 6. 6. 6.]]\n",
      "\n",
      "  [[0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [2. 2. 2. 2. 2.]\n",
      "   ...\n",
      "   [4. 4. 4. 4. 4.]\n",
      "   [5. 5. 5. 5. 5.]\n",
      "   [6. 6. 6. 6. 6.]]\n",
      "\n",
      "  [[0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [2. 2. 2. 2. 2.]\n",
      "   ...\n",
      "   [4. 4. 4. 4. 4.]\n",
      "   [5. 5. 5. 5. 5.]\n",
      "   [6. 6. 6. 6. 6.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [2. 2. 2. 2. 2.]\n",
      "   ...\n",
      "   [4. 4. 4. 4. 4.]\n",
      "   [5. 5. 5. 5. 5.]\n",
      "   [6. 6. 6. 6. 6.]]\n",
      "\n",
      "  [[0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [2. 2. 2. 2. 2.]\n",
      "   ...\n",
      "   [4. 4. 4. 4. 4.]\n",
      "   [5. 5. 5. 5. 5.]\n",
      "   [6. 6. 6. 6. 6.]]\n",
      "\n",
      "  [[0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [2. 2. 2. 2. 2.]\n",
      "   ...\n",
      "   [4. 4. 4. 4. 4.]\n",
      "   [5. 5. 5. 5. 5.]\n",
      "   [6. 6. 6. 6. 6.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [2. 2. 2. 2. 2.]\n",
      "   ...\n",
      "   [4. 4. 4. 4. 4.]\n",
      "   [5. 5. 5. 5. 5.]\n",
      "   [6. 6. 6. 6. 6.]]\n",
      "\n",
      "  [[0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [2. 2. 2. 2. 2.]\n",
      "   ...\n",
      "   [4. 4. 4. 4. 4.]\n",
      "   [5. 5. 5. 5. 5.]\n",
      "   [6. 6. 6. 6. 6.]]\n",
      "\n",
      "  [[0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [2. 2. 2. 2. 2.]\n",
      "   ...\n",
      "   [4. 4. 4. 4. 4.]\n",
      "   [5. 5. 5. 5. 5.]\n",
      "   [6. 6. 6. 6. 6.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [2. 2. 2. 2. 2.]\n",
      "   ...\n",
      "   [4. 4. 4. 4. 4.]\n",
      "   [5. 5. 5. 5. 5.]\n",
      "   [6. 6. 6. 6. 6.]]\n",
      "\n",
      "  [[0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [2. 2. 2. 2. 2.]\n",
      "   ...\n",
      "   [4. 4. 4. 4. 4.]\n",
      "   [5. 5. 5. 5. 5.]\n",
      "   [6. 6. 6. 6. 6.]]\n",
      "\n",
      "  [[0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [2. 2. 2. 2. 2.]\n",
      "   ...\n",
      "   [4. 4. 4. 4. 4.]\n",
      "   [5. 5. 5. 5. 5.]\n",
      "   [6. 6. 6. 6. 6.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [2. 2. 2. 2. 2.]\n",
      "   ...\n",
      "   [4. 4. 4. 4. 4.]\n",
      "   [5. 5. 5. 5. 5.]\n",
      "   [6. 6. 6. 6. 6.]]\n",
      "\n",
      "  [[0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [2. 2. 2. 2. 2.]\n",
      "   ...\n",
      "   [4. 4. 4. 4. 4.]\n",
      "   [5. 5. 5. 5. 5.]\n",
      "   [6. 6. 6. 6. 6.]]\n",
      "\n",
      "  [[0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [2. 2. 2. 2. 2.]\n",
      "   ...\n",
      "   [4. 4. 4. 4. 4.]\n",
      "   [5. 5. 5. 5. 5.]\n",
      "   [6. 6. 6. 6. 6.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [2. 2. 2. 2. 2.]\n",
      "   ...\n",
      "   [4. 4. 4. 4. 4.]\n",
      "   [5. 5. 5. 5. 5.]\n",
      "   [6. 6. 6. 6. 6.]]\n",
      "\n",
      "  [[0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [2. 2. 2. 2. 2.]\n",
      "   ...\n",
      "   [4. 4. 4. 4. 4.]\n",
      "   [5. 5. 5. 5. 5.]\n",
      "   [6. 6. 6. 6. 6.]]\n",
      "\n",
      "  [[0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [2. 2. 2. 2. 2.]\n",
      "   ...\n",
      "   [4. 4. 4. 4. 4.]\n",
      "   [5. 5. 5. 5. 5.]\n",
      "   [6. 6. 6. 6. 6.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [2. 2. 2. 2. 2.]\n",
      "   ...\n",
      "   [4. 4. 4. 4. 4.]\n",
      "   [5. 5. 5. 5. 5.]\n",
      "   [6. 6. 6. 6. 6.]]\n",
      "\n",
      "  [[0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [2. 2. 2. 2. 2.]\n",
      "   ...\n",
      "   [4. 4. 4. 4. 4.]\n",
      "   [5. 5. 5. 5. 5.]\n",
      "   [6. 6. 6. 6. 6.]]\n",
      "\n",
      "  [[0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [2. 2. 2. 2. 2.]\n",
      "   ...\n",
      "   [4. 4. 4. 4. 4.]\n",
      "   [5. 5. 5. 5. 5.]\n",
      "   [6. 6. 6. 6. 6.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [2. 2. 2. 2. 2.]\n",
      "   ...\n",
      "   [4. 4. 4. 4. 4.]\n",
      "   [5. 5. 5. 5. 5.]\n",
      "   [6. 6. 6. 6. 6.]]\n",
      "\n",
      "  [[0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [2. 2. 2. 2. 2.]\n",
      "   ...\n",
      "   [4. 4. 4. 4. 4.]\n",
      "   [5. 5. 5. 5. 5.]\n",
      "   [6. 6. 6. 6. 6.]]\n",
      "\n",
      "  [[0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [2. 2. 2. 2. 2.]\n",
      "   ...\n",
      "   [4. 4. 4. 4. 4.]\n",
      "   [5. 5. 5. 5. 5.]\n",
      "   [6. 6. 6. 6. 6.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [2. 2. 2. 2. 2.]\n",
      "   ...\n",
      "   [4. 4. 4. 4. 4.]\n",
      "   [5. 5. 5. 5. 5.]\n",
      "   [6. 6. 6. 6. 6.]]\n",
      "\n",
      "  [[0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [2. 2. 2. 2. 2.]\n",
      "   ...\n",
      "   [4. 4. 4. 4. 4.]\n",
      "   [5. 5. 5. 5. 5.]\n",
      "   [6. 6. 6. 6. 6.]]\n",
      "\n",
      "  [[0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [2. 2. 2. 2. 2.]\n",
      "   ...\n",
      "   [4. 4. 4. 4. 4.]\n",
      "   [5. 5. 5. 5. 5.]\n",
      "   [6. 6. 6. 6. 6.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [2. 2. 2. 2. 2.]\n",
      "   ...\n",
      "   [4. 4. 4. 4. 4.]\n",
      "   [5. 5. 5. 5. 5.]\n",
      "   [6. 6. 6. 6. 6.]]\n",
      "\n",
      "  [[0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [2. 2. 2. 2. 2.]\n",
      "   ...\n",
      "   [4. 4. 4. 4. 4.]\n",
      "   [5. 5. 5. 5. 5.]\n",
      "   [6. 6. 6. 6. 6.]]\n",
      "\n",
      "  [[0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [2. 2. 2. 2. 2.]\n",
      "   ...\n",
      "   [4. 4. 4. 4. 4.]\n",
      "   [5. 5. 5. 5. 5.]\n",
      "   [6. 6. 6. 6. 6.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [2. 2. 2. 2. 2.]\n",
      "   ...\n",
      "   [4. 4. 4. 4. 4.]\n",
      "   [5. 5. 5. 5. 5.]\n",
      "   [6. 6. 6. 6. 6.]]\n",
      "\n",
      "  [[0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [2. 2. 2. 2. 2.]\n",
      "   ...\n",
      "   [4. 4. 4. 4. 4.]\n",
      "   [5. 5. 5. 5. 5.]\n",
      "   [6. 6. 6. 6. 6.]]\n",
      "\n",
      "  [[0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [2. 2. 2. 2. 2.]\n",
      "   ...\n",
      "   [4. 4. 4. 4. 4.]\n",
      "   [5. 5. 5. 5. 5.]\n",
      "   [6. 6. 6. 6. 6.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [2. 2. 2. 2. 2.]\n",
      "   ...\n",
      "   [4. 4. 4. 4. 4.]\n",
      "   [5. 5. 5. 5. 5.]\n",
      "   [6. 6. 6. 6. 6.]]\n",
      "\n",
      "  [[0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [2. 2. 2. 2. 2.]\n",
      "   ...\n",
      "   [4. 4. 4. 4. 4.]\n",
      "   [5. 5. 5. 5. 5.]\n",
      "   [6. 6. 6. 6. 6.]]\n",
      "\n",
      "  [[0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [2. 2. 2. 2. 2.]\n",
      "   ...\n",
      "   [4. 4. 4. 4. 4.]\n",
      "   [5. 5. 5. 5. 5.]\n",
      "   [6. 6. 6. 6. 6.]]]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(offset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.offset = np.transpose(np.reshape(np.array([np.arange(self.cell_size)] * self.cell_size * self.boxes_per_cell), (self.boxes_per_cell, self.cell_size, self.cell_size)), (1, 2, 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
